First create a new service account from the console.

Go to Navigation menu > IAM & Admin, select Service accounts and click on + Create Service Account.

Fill necessary details with:

Service account name: bigquery-qwiklab
Now click Create and Continue and then add the following roles:

Bigquery > BigQuery Data Viewer
BigQuery > BigQuery User

Click Continue and then click Done.
Create a VM instance
In the console, go to Compute Engine > VM Instances, and click Create Instance.

In the Machine configuration:

Set the following values:

Configuration	Value
Name	bigquery-instance
Region	us-east1
Zone	us-east1-b
Series	E2
Machine Type	e2-medium
Click OS and storage.

Click Change to begin configuring your boot disk:

Boot Disk: Debian GNU/Linux 11 (bullseye) x86/64
Click Select.

Click Security.

Set the following values:

Configuration	Value
Service account	bigquery-qwiklab
Access scopes	Set access for each API
BigQuery	Enabled
Note: If the bigquery-qwiklab service account doesn't appear in the drop-down list, try typing the name into the "Filter" section.
Click Create.
Put the example code on a Compute Engine instance
In the console, go to Compute Engine > VM Instances.
SSH into bigquery-instance by clicking on the SSH button.
Note: While connecting to SSH, you can click on Connect without Identity-Aware Proxy.
In the SSH window, install the necessary dependencies by running the following commands:
a. sudo apt-get update
b. sudo apt-get install -y git python3-pip
c. pip3 install --upgrade pip
d . pip3 install google-cloud-bigquery
e. pip3 install pyarrow
f. pip3 install pandas
g. pip3 install db-dtypes
h. Now create the example Python file:

from google.auth import compute_engine
from google.cloud import bigquery

credentials = compute_engine.Credentials(
    service_account_email='YOUR_SERVICE_ACCOUNT')

query = '''
SELECT
  year,
  COUNT(1) as num_babies
FROM
  publicdata.samples.natality
WHERE
  year > 2000
GROUP BY
  year
'''

client = bigquery.Client(
    project='qwiklabs-gcp-00-d2dd7bf1ba3d',
    credentials=credentials)
print(client.query(query).to_dataframe())
" > query.py

## Add the Project ID to query.py with:

sed -i -e "s/qwiklabs-gcp-00-d2dd7bf1ba3d/$(gcloud config get-value project)/g" query.py


##Run the following to make sure that the sed command has successfully changed the Project ID in the file:
cat query.py
from google.auth import compute_engine
from google.cloud import bigquery
credentials = compute_engine.Credentials(
    service_account_email='bigquery-qwiklab@qwiklabs-gcp-00-d2dd7bf1ba3d.iam.gserviceaccount.com')

query = '''
SELECT
  year,
  COUNT(1) as num_babies
FROM
  publicdata.samples.natality
WHERE
  year > 2000
GROUP BY
  year
'''

client = bigquery.Client(
    project=qwiklabs-gcp-00-d2dd7bf1ba3d,
    credentials=credentials)
print(client.query(query).to_dataframe())

## The application now uses the permissions that are associated with this service account. Run the query with the following Python command:

python3 query.py

Row year  num_babies
0   2008  4255156
1   2006  4273225
2   2003  4096092
3   2004  4118907
4   2002  4027376
5   2005  4145619
6   2001  4031531
7   2007  4324008


